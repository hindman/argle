--------
api-vs-text: API-driven vs text-driven
--------

Two fundamental configuration strategies for argument parsers:

    - API-driven:

        - User configures a parser via the programmatic API.
        - The parser generates the help text.
        - Typically allows user to override with literal help text, if desired.
        - Examples: argparse and many others.

    - Text-driven:

        - User writes usage and options text.
        - Library derives the parser from that text.
        - This approach is much less common.
        - Examples: docopt.

The optopus library combines the best of both approaches:

    - API-driven.

        - Tends to require less typing.

        - Generated usage text is mostly fine, especially for simpler projects.

        - Most developers probably prefer an API-driven approach over
          hand-formatting help text themselves.

        - API-generated help text will follow the conventions for documenting
          command-line programs -- conventions that few developers have studied
          in depth and would rather not worry about.

    - Text-driven for grammar and naming:

        - Even though my experiments configuring argument parsers of varyig
          complexity via usage text convinced me of the benefits of an
          API-driven approach, text-driven option parsers have notable
          advantages. Those advantages are focused on command-line grammar and
          the associated naming for parsed data returned to the caller.

        - The text-driven approach emphasizes the idea of usage variants, a
          technique that can greatly enhance usage-text readability --
          especially for complex programs but also for small ones.

                git diff [<commit>] [--] [<path>...]
                git diff --cached [<commit>] [--] [<path>...]
                git diff <commit> <commit> [--] [<path>...]

                frob [--debug] [--foo <f>] <path>...
                frob --help
                frob --version

        - Usage variants open up a range of possibilities in the kinds of
          command-line grammars that can be supported. API-driven parsers
          struggle with command-lines that need any grammar falling beyond the
          most typical cases. On stackoverflow and bugs.python.org, for
          example, one can find many command-line use cases (some of them quite
          simple) that are not supported easily by argparse but that are
          straightforward in docopt.

        - Finally, usage syntax is both efficient and intuitive. When internet
          users discuss command-line grammar scenarios, they invariably use a
          usage syntax to specify the desired grammar. In my own research, I
          experimented with defining the needed grammars via an API, but I
          consistently found the text-based approach simpler to express and
          read.

Configuration via usage syntax is focused on grammar:

    - Optopus keeps that syntax fairly clean, readable, and intutive by
      focusing it solely on the grammar and naming -- the area where it excels.
      Other details, if any are neeeded, are handled via the API.

    - The syntax is also intuitive because it relies heavily on common
      conventions for documenting command-line programs.

    - The syntax will look roughly like familiar usage text, plus a small
      number of additional syntax elements focused on supporting flexible
      command-line grammar.

          - Usage variants. Discussed above.

          - Partial variants, which use the variant concept to define a named
            group of options and/or arguments that can then be inserted into
            one or more usage variants -- avoiding repetition in the definition
            of complex grammars (argparse does this via parents).

          - Named destinations for any group of elements in the grammar.

    - The syntax opens up a wide range of possibilities for complex programs or
      unusual grammars

    - But it also helps at the micro scale, simplifying the configuration of
      individual options.

--------
other-lib-weaknesses: Addressing weaknesses common in other libraries
--------

Providing users with simple ways to handle command-line grammars and usage
variants (just noted).

Supporting everything from quick-and-dirty scripts to complex, highly
customized command-line programs:

    - At once extreme, optopus allows you to parse any default-behavior
      command line, with zero configuration. Just import and go. This parser
      won't enforce any rules, but it will tell you what the end-user entered
      -- which is good enough for many types of quick-and-dirty scripts,
      debugging sessions, experiments, and even early prototypes.

            import optopus
            opts = optopus.parse_args()

    - At the other extreme, you could build the next Git or a variety of
      programs with idiosyncratic grammars, heavily customized help text, and
      many other features.

    - Sitting between the two extremes are numerous conveniences and sensible
      defaults to make option parsing easy, no matter what level of control
      your application needs.

Allowing users to control the generated help text in a fine-grained manner.

    - Program complexity increases the need to organize and fine-tune help
      text, but not necessarily to write and layout the whole thing
      (text-driven libraries require that).

    - Optopus provides many mechanisms for that fine tuning:

        - Simple top-level configurations to control basic layout,
          capitalization, punctuation, etc.

        - Ability to group options into sections.

        - Ability to supply hand-crafted sections whenever needed and to locate
          those sections with precision in the output.

        - Ability to control nearly all parameters driving the help text
          contruction process via configuration and, where necessary, through
          the programmatic hooks. There should be no need to subclass optopus
          or delve into the parser's innards.

        - Support for common styles: command-line vs man-page.

Allowing users to enhance usage-text readability by being able to refer to
groups of options and to omit either short or long options.

    - API-generated usage text tends to be poor not only because it lacks usage
      variants but also because the generated text exhaustively lists all
      options in all of their permutations (short and long).

    - Especially as the number of options grows, readability can be improved
      greatly by referring to sets of options by symbolic names rather than by
      enumerating every possibility.

    - Similarly, readability can be enhanced by focusing the usage text on just
      the long-options (or just the short-options) and then providing a mapping
      between short and long options latter in the help text.

Allowing users to define their arguments and options in ways that encourage
modularity.

    - In optopus a user defines/configures options and arguments as atomic
      units, separate from the issues of command-line grammar, usage variants,
      and options help text.

    - Each of those atomic units can be attached to one or more groups of
      related options.

    - Then those options or option-groups can be leveraged when defining the
      command-line grammar, when expressing the generated usage text, and when
      organizing the options text into sections.

Providing users with full access to the parser configuration, both via the API
and in the form of standard, serializable data structures.

Providing users more conventient mechanisms to reduce repetition in
the configuration of the parser.

--------
other-goals: Other goals
--------

Prioritize the simple use cases. Yes, add features and customization
capability. But do that without sacrificing super super usage patterns.

Usage should be intuitive and declarative, especially for the simplest and most
common use cases. It should not depend on bizarre syntax or on user-created
complex data structures.

The parser's configuration should be expressible as a data structure -- and
creatable from one. This is important for testing, debugging, easy integration
with config files, and using other libraries for data validation.

For complex programs or special needs, users should have full control over
documentation. This includes both usage/help text and the styling of error
messages.

Easy system for validators to be combined flexibly.

Should easily support different help types: (a) brief usage/synopsis, (b) full
help or man-page, and (c) extras or examples.

Include ability to merge options from several sources: ENV variables, config
files, command-line options. Note that the purpose of the configuration sources
(ENV vars and config files) is to set the default values used by the
command-line option parser. When defaults are supplied, it should also cause a
required option to become non-required (in other words, whenever default is set
for an option, it causes required to become False.

Make it easy to test the option parser.

Error handling should be under the user's control, if they want it. This is a
serious flaw in some parsers (eg argparse). The library should support both
"automatic" mode (where the parser will eagerly print help or error message and
then exit) or non-automatic mode (where the parser will simply return an object
containing all information and allow the user to decide what to do. [Note that
argparse has addressed this, in whole or in part, in Python 3.9].

Should have a design that is friendly to customization. Allow users to
customize by writing simple functions or hooks rather than having to subclass.
Consider using the pluggy library so that users can implement simple function
hooks.

Start simple: begin with core behaviors; don't support more flexibility until a
basic working system is in place.

Where possible, rely on convention over configuration: sensible defaults to
allow the most common path to be followed with minimal setup.

Provide good support for --version. Show the application's name and version
number.

Provide helper functions for warn(), exit().

Support various configuration styles: per option configuration (argparse and
many other libraries do this); and thematic or bulk (make one type of setting
on multiple options at once).

Allow the user to have hidden options (eg for developers only).

Support file and dir types as arguments, with checks for existence or non-existence.

For file path arguments, support the ability to treat `-` as stdin or stdout.

Support an easy way to get bash completion.

Support @somefile.txt: user supplies command-line args via a file.

Support parse_known_args().

Support abbreviated option names when there is no ambiguity.

Support some no-configuration argument parsing strategies: default (options are
flags), key-val (options take single args by default), greedy (options consume
as many params as possible).

Support conversion/validation.

Support dispatch mechanisms.

The parser's configuration is likely to be organized as a fairly deep tree
behind the scenes. But make it easy for the user to query that tree to obtain
nodes of interest for configuration and other purposes. Primarily this means
quickly getting Opt instances, but there could be other types of interest as
well.

Let users control the important aspects of the help text: section ordering;
section titles; layout style (eg, compact 2-column or man-page); capitalization
rules; widths; conventions for showing default values; etc.

--------
standard-cli-grammar: Standard command-line grammar
--------

Typical rules of command-line grammar, as commonly understood in Unix tradition:

    - Options start with a prefix:

        --long
        -s

    - Options can take zero or more ordered parameters.

    - Positional arguments are ordered among each other:

        P1 P2 P3 ...

    - Options can be ordered in any way:

        --x4 --x1 --x3 --x2 ...

    - Options can be freely interspersed among the ordered positional arguments.

        --x3 P1 --x1 --x4 P2 --x2 P3 ...

    - Short options can be bundled:

        -x -y -z
        -xyz

--------
cli-grammar-vs-regex: Command-line grammar vs. regex
--------

Although Optopus usage syntax borrows many concepts from regular expressions,
command-line grammar parsing is not readily amenable to handling via regex
parsing approaches.

Positionals are ordered among themselves, but options can appear in any order
(ignoring boundaries and anchors). That flexibility makes it not very intuitive
to convert a command-line grammar into a manageable regular expression. At
every stage, any of the options are possible. But then once an option appears,
it cannot appear again (ignoring repeatables). That means command-line parsing
is context-sensitive.

--------
subparsers-not-needed: Optopus does not need the subparser concept
--------

The subparser concept is much less powerful and flexible than the key concept
of a command-line grammar, along with the related ideas of usage variants and
flexible destination assignment. It's also less intuitive.

The universe of command-line programs could be broken down into a sizable
majority and two small minorities:

    - A sizable majority that needs neither subparsers nor a complex grammar.

    - A small minority that align conceptually with the subparser concept. But
      command-line grammar supports this use case even better.

    - A small minority that are forced by the limitations of current argument
      parsing libraries to resort to subparsers even though the concept does
      not align very well with their needs.

--------
opt-action-not-needed: Optopus does not need the action concept
--------

Arguments can be configured in argparse with an 'action' parameter. The
parameter is a bit overloaded and misleading. It does control some actions (eg,
showing help text), but mostly it is used as a sometimes misnamed device for option type
and destination assignment.

    Action       | Option type       | Example         | Stored      | Notes
    ----------------------------------------------------------------------------------
    store_true   | 1 flag            | --frob          | True        | True == 1
    store_false  | 1 flag            | --frob          | False       | To override a True default
    count        | 1+ flags          | -v -v           | N           | .
    store        | Single            | --foo F         | F           | .
    append       | Repeatable single | -x A -x B       | [A, B]      | Overwrite on repeat
    extend       | Repeatable multi  | -x A B -x C D E | [A B C D E] | .
    help         | High precedence   | .               |             | .
    version      | "    "            | .               | .           | .
    ----------------------------------------------------------------------------------
    store_const  | 1 flag            | --frob          | X           | Not necessary
    append_const | 1+ flag           | --frob --frob   | [X x]       | Not necessary

--------
explicit-option-param-syntax: Why explicit syntax for option parameters is needed
--------

Imagine that the grammar did not require explicit surrouding markers for
parameters, positionals, and literal values: {}, <>, an ''. Every type of
confusion would be possible.

    frob --type x y z   # Meaning of x, y, z unclear.

Some ways to address that problem:

    - Minimize syntax burden. Require that literals be quoted (because rarely
      needed) and positionals use angle brackets (because it is conventional).

    - Enforce consistency: require all 3 types of markers (and because braces
      for params are also conventional).

    - Be creative: require that literals be quoted and give users a mechanism
      to disambiguate when needed. Probably a bad idea: these issues can be
      tricky to think through. Also, for non-standard grammars, a small bit of
      extra typing seems easy compared to having to reason about subleties.

--------
high-precendence-options: High precedence options
--------

Most options control the primary behaviors of a program. But some are
special, most notably those related to user help:

    --help
    --version
    --examples
    --demo

Argument parsing libraries often provide an convenient mechanism for --help and
sometimes --version, but rarely anything else. In addition, they tend to
provide such features in a way that is slightly misleading (at least in a
strict sense) and definitely not as convenient for users as it could be.

Consider a simple subcommand-style program. Assume that both <id> and the
parameter for -n should be integers and that the program has both general help
text and subcommand help text.

    demo [--help] [-n {}] (print|delete) <id>

At least by default, if the end-user supplies the --help option, an argument
parser should (1) print help text and exit, (2) select the help text that is
relevant given the other command-line arguments, and (3) ignore errors in the
other command-line arguments. Some examples of desired behavior:

    demo --help                # General help.
    demo --help delete         # Delete help.
    demo --help -n HI delete   # Same, in spite of invalid -n parameter.

Most argument parsers fail on #3 (they gripe instead of helping) and they do
not easily support #2.

Optopus addresses those problems with two mechanisms: high-precendence options
and flexible dispatching. If an option is configured to be high-precendence,
its presence among the command-line arguments will trigger whatever action it
has been configured to perform, and that dispatching configuration will take
precendence over error reporting. When high-precendence options are used, the
parser performs a best-effort parsing to collect as much contextual information
as it can before calling the code responsible taking action.

There are limits, of course. Some types of bad input can reduce the accuracy of
that best-effort parse. In this example, -Q in an unknown option and is treated
by default as a flag taking no parameters, which then means that HI is is
interpretted an invalid subcommand.

    demo --help -Q HI delete   # General help rather than delete help.

--------
help-text-formatting: Help text formatting
--------

Text wrapping:

    - Respect terminal widths, if known and within boundaries:

        min_width = 40
        max_width = 100

    - Allow users to adjust those parameters.

    - User-supplied text:

        - Break into paragraphs (but preserve info about N of blank lines
          between paragraphs).

        - Rewrap to the desired width (probably using textwrap module).

        - Leave indented paragraphs as-is.

        - Provide an easy syntax for users to suppress line wrapping
          within the text (eg something borrowed from markdown)

--------
grammar-parsing-algo: Parsing the grammar syntax
--------

Phase 1: input normalization:

    - Accept text and/or lines of text.
    - Join into a block of text.

Phase 2: lexing:

    - Remember that the lexer analyzes character by character to emit
      a flat streem of the meaningful atomic units of the language.

    - It does not engage in validation logic to assess whether the arrangement
      of those units is syntactically valid.

    - Nor does it try to assemble those character-based atoms into fully
      meaningful entitities, other than in cases where they must be assemble to
      avoid ambiguitity with similar tokens.

    - Regex snippets to build the token regexes:

        Spippets | Pattern
        ------------------------------------------
        letter   | [A-Za-z]
        nm       | letter (letter | \d)*
        name     | nm ([-_] nm)*

    - Token names and regexes, in order of evaluation:

        Tokens            | Pattern
        ------------------------------------------
        quoted-literal    | '[^']+?'
        newline           | \n          emit=False
        whitespace        | \s+         emit=False
        quantifier-range  | \{ \s* ( \d+ | \d+ \s* , | \d+ \s* , \s* \d+ ) \s* \}
        paren-open        | \(
        paren-close       | \)
        brack-open        | \[
        brack-close       | \]
        brace-open        | \{
        brace-close       | \}
        angle-open        | \<
        angle-close       | \>
        choice-sep        | BAR
        zero-or-more      | \*
        one-or-more       | +
        one-or-more-dots  | \.\.\.
        question          | \?
        assign            | =
        long-option       | -- name
        short-option      | - letter
        partial-defintion | name ` \s* :
        variant-defintion | name \s* :
        continuation      | :
        partial-usage     | name `
        name              | name
        number            | \d+
        nameless-param    | _

Phase 3: parsing:

    - A parser's job is to eat a stream of tokens, organizing them into
      meaningful and valid units, and emitting those units to the caller.

        - Previously, I tried to write the lexer code with a parsing mindset.
          That was too hard.

        - Now we just have to figure out how to organize the consumption of the
          tokens listed above.

    - Focus now on the full grammar. Convenience syntax can be handle later via
      a different subclass, different tokens, different parser functions, or
      some combo.

    - Parser functions should be substantive from the perspective of the
      language, not low level.

    - Since a grammar is just a sequence of Variant, the mixin
      will be given just one parser function. The more fine-grained method
      calling will occur in the subclass. [Subsequently decided
      to drop the mixin.]

    - See draft.py for draft of the parser functions and some related
      changes to RegexLexer.

Phase 4: interpretation:

    - Reassess whether this phase is a good idea: leaning in that
      direction.

    - The parser phase is the most complex, so don't overburden it
      with the duty of creating the ultimate grammar elements.

    - Instead, keep the parser simpler by having it emit simple AST-style
      objects.

    - The last phase converts the AST to true grammar elements.

--------
convenience-parsing-algo: Parsing the convenience grammar syntax
--------

The grammar can be built from the parts we already have:

    P1         = positional | positional_definition
    P2         = [ P1 ]

    O1         = short_option | long_option
    O2         = parameter | parameter_definition
    O3         = [ O2 ]

    single_pos = P1+ P2*
    single_opt = O1 O2+ O3*

Apply extra validation at the end to disallow:

    Only a single Opt (if P1 repeats, they must have same dest).
    Group
    PositionalVariant
    ParameterVariant

To orchestrate things we can adjust the GrammarParser initializer:

    def __init__(self, text, single = False):
        self.lexer = RegexLexer(text, GRAMMAR_TOKENS)
        if single:
            self.parser_functions = (self.single_pos, self.single_opt)
        else:
            self.parser_functions = (self.variant,)

--------
arg-parsing-algo: Parsing algorithm
--------

Notation and terminology:

    - Purely notational concepts:

        Pos:         A positional Opt.
        MGroup:      A Group having mutex=True.
        Alternative: A Variant or MGroup.
        OPT:         When current arg looks like an Opt.
        POS:         When current arg looks like a Pos.

    - Parsing terms:

        - Alternatives: the Variants and MGroups determine how many
          alternatives we will try.

        - Interpretations: within an alternative, there can be multiple valid
          interpretations of the arguments -- specifically how they are
          allocated to Opts either as positionals or params.

        - Backtracking terms:

            - Current interpretation or parsing route: the interpretation you
              are currently on, based on a successful parse of the current arg.

            - Foregone interpretation: the interpretation that you could have
              selected, but did not -- so you push it to the stack before proceeding
              with the current interpretation.

Some key insights related to backtracking:

    - Parsing decisions that might require backtracking come from positional
      arguments or parameters, not options. Options, if present, are
      non-ambiguous: either they are known and allowed, or not.

    - Backtracking is needed when your current parsing route ends up attaching
      a param to an Opt or an argument to a Pos but then that route ultimately
      fails (on a later argument). You need to backtrack to check any foregone
      alternative interpretations of the input arguments.

    - Alternative interpretations are possible only for Opt with non-static
      nparams, Pos with non-static nargs, or Pos with non-static ntimes.

    - So pushing to the stack needs to happen when your parsing decision for
      the current argument creates a foregone alternative.

    - This occurs only for successful parsing of the current argument; never
      for errors.

    - Variants and MGroups also don't require a backtracking mechanism.

        - Rather, you want to process all of the alternatives in order, based
          on the Grammar. Each alternative either succeeds or fails. And you
          stop on the first success.

        - The best time to load the stack with these alternatives is before the
          while-stack loop begins. This will ensure that each alternative will
          be tried in order. Because we are using a stack, backtracking within
          any specific alternative (due to non-static nparams/nargs) will
          finish before the algorithm advances to a fresh alternative.

        - If you were to try to push foregone interpretations to the stack when
          an alternative fails, you interfere with the correct ordering of the
          alternatives. Perhaps even worse, it's not easy to know within the
          while-stack loop when an alternative has totally failed. Each
          iteration of the loop can be either starting a fresh alternative or
          exploring one of the different interpretations possible within the
          alternative.

A backtracking example:

    Grammar:
        Opt('-f', nparams = (1,3))
        Opt('x', nargs = (3,4))

    Input:
        -f V1 V2 V3 V4 V5

    Parsing logic:

        -f : Valid: attach it to Opt(-f).

        V1 : Attach to Opt(-f)

        V2 : Because Opt(-f) is greedy by default, attach. But
             this attachment is not required due to non-static
             nparams. Before pushing the new State where V2
             is attached to Opt(-f), we should push the foregone
             interpretation -- namely, where we restrict Opt(-f)
             to nparams of (1,1).

        V3 : Same logic: attach and push foregone interpretation.

        V4 : Attach to Opt(x).

        V5 : Same.

        -  : Now we're out of arguments and have not
             satisfied Opt(x). So this interpretation fails.
             The next State in the stack will restrict
             Opt(-f) to nparams of (2,2), which will succeed.

    Logic if Opt(-f) had been non-greedy.

        V2 : Don't attach to Opt(-f). Now the foregone interpretation
             is for Opt(-f) with nparams of (2,3). Push that
             to the stack.

State:

    - Data object to hold parsing state as the various interpretations from the
      grammar are being tried during the while-stack loop.

    - Attributes:

        ai: index of args.

        next_pos: next available Pos [or None].

        nps: nparams remaining for the active Opt [or None].

        avail: map of available Opt to remaining ntimes [0 for exhausted].

        target: Target instance holding parsed data accumulated so far.

        err: error that terminated the current alterantive [or None].

        variant: name/id/index for the current variant; relevant for
        error selection/reporting, not parsing directly.

ArgResult:

    Data object to represent info need to capture the result-so-far
    for the parsing the current arg. Some likely attributes:

        err: data object holding error info
        opt: matched Opt
        val: converted value

    Notation used here:

        ArgResult(ERR: ...) | Current arg failed.
        ArgResult(OPT)      | Current arg matched OPT.
        ArgResult(PARAM)    | Current arg matched PARAM.
        ArgResult(POS)      | Current arg matched POS.
        ArgResult(UNKNOWN)  | For forge-ahead-mode or parse-known-mode.

How to handle optional Groups:

    - A Group can be optional overall, but have required elements if
      the Group is triggered by the presence of any of its elements.
      For example, if either -x or -y are present, both are needed.

        [ -x -y [-i] ]

    - When to handle such matters:

        - During parse. For example, when we see -x, then we would
          immediately adjust ntimes for -y.

        - After a successfull ArgResult. Before checking Opts for sufficient
          nparams, nargs, ntimes, we would first adjust those expectations
          based on any Groups that were activated by the presence of the Opts.

    - The latter, for two reasons:

        - Groups can alter quantifier expections. It makes sense to do all of
          that quantifier checking together.

        - More fundamentally, an optional Group can contain positionals and
          params. Like in the rest of the grammar, greedy is the default. That
          means positionals within optional Groups should be attached eagerly.
          It could get very messy trying to support some special logic just for
          optional Groups. The user has multiple ways to configure the grammar
          if the default greediness isn't desired.

Algorithm: setup:

    Stuff from the end-user or user:

        args = [...]

        P = Parser(...)
        G = P.grammar

    Initialize the stack that drives the algorithm. For every allowed combo of
    Variant and MGroup, add a State instance to represent the initial
    conditions of each alternative.

        # The stack of States.
        stack = [S1, S2, ...]
        stack = list(reversed(stack))

        # Every State examined and whether the entire parse is complete.
        history = []
        success = False

        # Parser-wide inventory of all known OPT.
        known_opts = G.get_all_options()

Algorithm: parsing loop:

    while stack and not success:

        # Prep.

        S = stack.pop()
        arg = args[S.ai]
        T = P.get_arg_type(arg)
        ares = ArgResult()

        # Check arg type.

        if T is OPT:

            # Handle aliases and fuzzy match.
            if arg not in S.avail:
                arg = P.fuzzy_match(arg)

            if arg not in known_opts:
                ares = ArgResult(ERR: globally unknown OPT)
            elif arg not in S.avail:
                ares = ArgResult(ERR: inapplicable OPT)
            elif S.nps is not None:
                ares = ArgResult(ERR: expected param but got OPT)
            elif S.avail[arg] == 0:
                ares = ArgResult(ERR: OPT occurred too many times)
            else:
                ares = ArgResult(OPT)

        else:
            if S.nps[arg]:
                ares = ArgResult(PARAM)
            elif S.next_pos is not None:
                ares = ArgResult(POS)
            else:
                ares = ArgResult(ERR: too many POS arguments)

        # Conversion and validation for PARAM and POS.

        if not ares.ERR and not ares.OPT:
            null = object()
            val = null
            ok = null
            err = None
            try:
                val = ares.opt.convert(arg)
                ok = ares.opt.validate(val)
            except (...) as e:
                ares.err = captured info about the error

            if ok is not True and (forge-ahead-mode or parse-known-mode):
                # Treat as success.
                ares.best_effort = True
                ares.val = arg
            elif val is null:
                ares = ArgResult(ERR: conversion raised an error)
            elif ok is null:
                ares = ArgResult(ERR: validation raised an error)
            elif ok is False:
                ares = ArgResult(ERR: validation returned False)
            else:
                # Success.
                ares.val = val

        # Handle less restrictive parsing modes.

        if ares.ERR and (forge-ahead-mode or parse-known-mode):
            ares = ArgResult(UNKNOWN)

        # Check for overall success if args exhausted.

        if ares.ERR is None and S.ai + 1 == len(args):

            - First check whether any Groups have been activated by the present
              Opts. If so, adjust expected ntimes accordingly.

            - Then check that all Opts have sufficient nparams, nargs, ntimes.

            if OK:
                success = True
            else:
                ares = ArgResult(ERR: insufficient ntimes/nparams/nargs)

        # Store history, push foregone, check overall success.

        if ares.ERR:
            # On error, just store the history.
            S.target.add(ares)
            history.append(S)

        else:

            # Check for foregone interpretation.
            # Not yet sure if we should perform these steps for ArgResult(UNKNOWN).
            if not success and (ares.PARAM or ares.POS):
                If either of these apply:
                    - Matched Opt has non-static nparams.
                    - Match Pos has non-static nargs or ntimes.
                Then:
                    S2 = new State to represent the foregone parsing route
                    stack.push(S2)

            # Store history.
            S.target.add(ares)
            history.append(S)

            # Create next parsing State.
            S1 = new State based on current parsing route
            stack.push(S1)

Algorithm: wrap up:

    if success:
        return history[-1].target

    else:
        - Examine history to find most relevant error.
        - Return or raise, depending on Parser configuration.

Post-parsing logic:

    target = self.do_parse(...)

    Load the data from target into a Result. Details will vary based on Parser
    configuration and parsing-mode.

--------
alternative-parsing-algo: Alternative parsing algorithm won't work after all
--------

The algorithm:

    - When parse() is called, there will be N command line arguments.
      Command-line use cases never have large N.

    - Using the parser configuration, assemble data on the aspects of the
      grammar that are not static. The most common non-static configurations:
      varying nargs, nparams, or ntimes; variants; and alternatives.

    - For grammar elements that have no inherent boundaries (eg, an option
      taking 1+ params), interpret them in as bounded by using N as the upper
      limit.

    - Use all of that information to generate all static grammars that satisfy
      the actual grammar.

    - Check each static grammar against the command line arguments.

    - A successful parse finds exactly one successful static grammar.

What causes a grammar to generate multiple possibilities?

    .                     | Where expressed | Note
    -----------------------------------------------------
    Varying nargs/nparams | Opt             | .
    Varying ntimes        | Opt or Phrase   | Includes required.
    Alternatives          | Phrase          | Includes variants.
    Aliases               | Opt             | .

Benefits of the algorithm:

    - This code seems easy to write:

        - The generation of static grammars seems like a manageable
          situation involving itertools.

        - Parsing a static grammar very simple: no backtracking required.

    - It provides a run-time guard for users against ambiguous grammars.

Three concerns:

    - The approach seems non-standard. A classic stack algorithm seems to suit
      the situation. And that code might not be any harder to write -- perhaps
      just a bit less familiar. Why reinvent the wheel? Make sure there's a
      good reason.

    - Modern operating systems and shells have very large limits on the max
      size of command lines and N of arguments. Why build a good argument
      parsing tool that would fail at moderate values for N -- especially
      when a linear algorithm is known?

    - There won't necessarily be only one successful parse of the static
      grammars, as noted in the discussion of ambiguous grammars. By using a
      greedy assignment policy the parser can ignore that matter. But regular
      expressions have a greedy concept precisely because without it there can
      be more than one successful parse of an input. [On further reflection,
      this point argues against expecting only one successful static grammar.
      But if you try the static grammars in the correct order, based on greedy
      policies in place, you can stop at the first success -- as regex does.]

--------
ambiguous-grammars: Ambiguous grammars are not an issue
--------

From a strictly grammatical perspective, only one positional can have a
non-static nargs or ntimes, because there isn't exactly one valid way to attach
the values to the destination attributes. A similar problem occurs when an
option has non-static nparams and a positional has non-static nargs.
Two examples:

    <xray>...    <y>...
    --xray {}... <y>...

But that's not a problem, because Optopus can do what regular expression
engines do: greedy assignment by default, non-greedy by configuration.

--------
parsed-data-structure: Parsed data structuring: nargs, nparams, ntimes
--------

The meaning of nparams, nargs, and ntimes:

    nparams : N of params (for options)
    nargs   : N args (for positionals)
    ntimes  : Governs only optionality and repetition via {n,m} or its shortcuts.

    Options:                    #  nparams  ntimes

        -y                      #  0        (1,1)
        [-y]                    #  0        (0,1)
        [-y {} {}]              #  2        (0,1)

    Positionals:                #  nargs    ntimes

        <x>                     #  1        (1,1)
        [<x>]                   #  1        (0,1)
        (<x> <x> <x>){0,2}      #  3        (0,2)
        -----------------------------------------
        <x> <x> <x>             #  3        (1,1)      # A
        <x>{3}                  #  1        (3,3)      # B

Is nargs needed? Why not handle it all with ntimes? See the examples marked A
and B above. There is a subtle difference between the two configurations in the
returned data, if the user requests non-flattened. Example A would produce [X1,
X2, X2], but example B would create [[X1], [X2], [X3]]. Generally, users should
prefer to configure positionals with nargs first, using ntimes only when
required.

Internally, all data assigned to destinations will be stored in a fully
explicit manner. Assume a list of lists, where nargs/nparams determines the
length of the innermost lists and ntimes determines the length of the outer
list(s).

    - Singular nargs, nparams, and ntimes:

        a1     # Either value or bool (latter if nargs/nparams is zero).

    - Add plural nargs/nparams:

        [a1, a2, ...]

    - Add plural ntimes:

        -x _ _ (<z> <z>){3}

        x = [a1, a2]

        z = [[a1, a2], ..., ...]

    - Add a layer of nested plural ntimes:

        (  --foo _ _  (-x _ _ <z> <z>){3}  ){4}

        foo: nparams 2, ntimes     4
        x  : nparams 2, ntimes 3 x 4
        z  : nargs   2, ntimes 3 x 4

        foo = [[a1, a2], ..., ..., ...]

        x = [
            [[a1, a2], ..., ...],
            ...
            ...
            ...
        ]

        z = Same structure as x.

Default flattening policy:

    - If the grammar does not contain nested plural ntimes, data
      will be flattened as much as possible, as shown in table below.

    - User can request non-flattened data or flattened (the latted
      to flatten even the 2x2 or nested scenarios).

    nargs or | ntimes    | ntimes 2+                   | ntimes 2+
    nparams  | 0 or 1    | Flattened                   | Non-flattened
    ------------------------------------------------------------------
    0        | bool      | [bool, ...]                 | [[bool], ...]
    1        | a1        | [a1, ...]                   | [[a1], ...]
    2+       | [a1, ...] | [[a1, ...], [a1, ...], ...] | .

--------
eager-attachment-at-bounary: Eager option attachment at repetition boundaries
--------

In the following example, the -z option will bind eagerly to the repeated
triplets of positionals.

    Grammar:                  cmds=(<a> <b> <c> [-z]){2,7}
    Example input:            A1 B1 C1 -z A2 B2 C2
    Returned data for cmds:   opts.cmds[1] = Namespace(a=A1, b=B1, c=C1, z=False)

That policy is consistent with greedy parsing elsewhere. Configuration for this
issue will have to be done via the API.

--------
grammar-syntax-named-unnamed: Grammar syntax: named and unnamed arguments
--------

Positionals must be named:

    frob <a> <b> [<c>]

Option arguments can be named or unnamed:

                                        # opts.mode:
    frob --mode {group} {name} {n}      # - Data object with attributes.
    frob --mode {} {} {}                # - Tuple.

--------
variants-needed: Variants: why they are needed
--------

Are variants needed give that the grammar syntax already has support for
alternatives?

Partial variants are a useful device to express some grammars more
conveniently.

Usage variants are a good mechanism for the user to help Optopus generate more
readable usage text and more relevant portions of it in response to errors.

Variants can provide a low-config mechanism for subcommand-style programs to
provide subcommand help text.

Variants have been a useful concept, and their names convenient handles, when
thinking about and planning this project. That utility might come in handy
later.

So one might think of the following related concepts, from most general
to most specific:

    Group           # Any grouping of grammar elements.
    Alternative     # A grouping where the end-user should choose one.
    Variant         # An alterantive that strongly affects usage text.

--------
destination-assignment: General destination assignment: needed after all
--------

Optopus does need generalized destination assignment. At a minimum, it needs
that feature not just for Opt, but also for partial variants. And once you go
that far, you might as well generalize it.

Consider examples like neck-diagram (nab is similar). With destination
assignment, the specific Opt destinations (cmd, snum, syms, etc) will be nested
underneath the 'commands' namespace (the outer destination assignment). The returned
data would have this structure:

    opts.commands : (
        Namespace(cmd = 'snum', snum = 6),
        Namespace(cmd = 'tuning', notes = ('E', 'A', ...)),
        Namespace(cmd = 'fret', syms = ('1', '3', '5')),
        ...
    )

Without the outer assignment, the returned data would be grouped by the Opt
destination names -- which badly jumbles everything up:

    opts = Namespace(
        cmd   : ['snum, 'tuning', 'fnum', 'fret', 'fret', ...]
        snum  : ['6']
        fnum  : ['5']
        notes : [[...]]
        syms  : [[...], [...], ]
    )

--------
grammar-syntax-complexity: Grammar syntax: is it too complex?
--------

To evaluate the question, I focused on the least intuitive aspect of the syntax
and compared it against the API-driven alternative:

Alternatives:

    - This is an easy call: syntax is intuitive and API usage for this
      situation is annoying.

    - This is a strong example of the superiority of text syntax for grammar
      configuration relative to API.

Quantifiers:

    - The ... is intuitive and practically a convention.

    - The {m,n} syntax directly mimics regex and is also quite intutive.

General destination assignment:

    - This feature is powerful: it allows grammar variation when
      a positional or parameter takes a specific value.

    - Configuring such matters via the API requires the user to understand how
      the library works a bit too closely.

Partials:

    - API usage would require the user make multiple configurations to mark a
      variant as partial and then insert it wherever needed.

    - The partial syntax isn't heavy; in fact, it's moderately intuitve and
      without it, the grammar syntax might even be a bit less immediately
      understandable.

Zones and anchoring:

    - I suspect the desire for zones and anchoring is moderately low but still
      more than nothing.

    - Also, configuring these parameters via the API is simple to understand
      and requires little code.

    - While the zone syntax not too obtrusive, and it is a mixture of intuitive
      (zone markers) and not very intuitive (anchor markers)

    - Infrequent use case, easy to handle via API: let's drop it from grammar syntax.

    - Another question: is the zone concept needed, or could Group do the same
      thing? I increasingly think so.

High precedence:

    - Setting this attribute is easy in the API.

    - Although the syntax is not heavy, it's also not fully intuitive.

    - The majority of use cases will get the built-in help behavior, and the
      library could interpret --help and --version options as high precedence
      by default.

    - Infrequent use case, easy via the API: let's drop it.

--------
optional-positional-placement: Optional positionals before required are not a problem
--------

One might be concerned about Grammars containing optional positionals before
required ones. For example:

    [<m>] <x> <y>

But this is not a problem is we just adhere consistently to greedy policy.
If the user wants positionals attached to <x> and <y> before <m>, they
can express the grammar differently.

--------
parse-known-args: Parse known arguments
--------

How argparse handles it:

    - Instead of returning a single Namespace it returns a tuple:

        (Namespace, List[unknown args])

    - It does still apply all validations to any supplied arguments.

I have found that approach mildly annoying:

    - It requires a change to the calling code to call a different
      method and to unpack the 2-tuple.

    - That makes it a bit less convenient to drive via typical configuration
      mechanisms.

I think it makes more sense for Optopus to treat parse-known-args as one of the
parsing modes that it supports:

    Parsing modes:

        Configured: these modes can be combined. They relax the rules to allow
        deviations:

            allow-unknown
            allow-unconverted
            allow-invalid

        No configuration: these modes are exclusive:

            Mode    | nparams
            -----------------
            flag    | 0
            key-val | 1
            greedy  | 0+

Optopus:

    - By default:

        - Continue to return a single Result object.

        - Put the unknown arguments in an attribute with an uncommon name, such
          as 'others' or 'unknowns'.

    - Let the user configure this:

        - Name of the unknowns attribute.

        - Whether to return (Result, List[unknowns]) tuple, like argparse.

--------
destination-scopes: Destination scopes
--------

By default, a destination used in multiple places within a grammar are assumed
to refer to the same underlying Opt.

    Example 1:

        <x> <x>

    Example 2:

        foo : <x> [-y]
        bar : -z -y <x> <x>

    Example 3:

        foo : <x> [-y]
        bar : -z -y [-x]

    Example 4:

        foo : <x> [-y]
        bar : -z -y <x>

It seems like the right default behavior, but it opens up some questions:

    (1) What if the grammar contains two or more fundamentally different Opt
    types for the same destination, as in Example 3?

    (2) What if the user wants different configuration for the same destination
    in different locations within the grammar? The nab script, for example,
    seems to demand this kind of flexibility: each nab command needs its Opts
    to be independently configurable.

One approach:

    - Disallow Opt independence within a variant: if you use the same
      destination in a variant, the underlying Opt will be the same.

    - Use Opt independence across variants.

    - In some cases, the grammar will force independence right out of the gate,
      as in Examples 2 and 3. This will occur if the grammar implies differents
      in Opt types, nparams, nargs, ntimes.

    - In other cases (such as Example 4) the variants won't distinguish
      the Opts.

    - Flexible querying mechanisms can support easy configuration whether
      the user wants to configure different occurrences of the same destination
      differently or the same. Under the hood, the Opts will be distinct, but
      the user won't have to think too hard either way:

        p = Parser(...)
        p.get('x').config(...)         # Configures both <x> Opts.
        p.get('foo', 'x').config(...)  # Configures only <x> in Variant(foo).

--------
zones-not-needed: Zones not needed
--------

In my planning I think the concept of Zones was not useful. A zone has no
purpose on its own; rather, it existed purely to support anchoring. And the
anchoring configuration was applied to Opts, not Zones. Just use Groups and
allow Opts to be anchored within them.

--------
help-distpatching: Help distpatching
--------

Optopus aims to support behavior like this:

    frob --help              # Print general help.
    frob configure --help    # Print help for the configure task.

How does the user configure this help dispatching. More generally, what about
supporting other help-printing scenarios that rely not on --help but on some
other options: for example, I've had programs where I want --examples to print
some usage examples for the end-user.

    - Simple use case: standard help feature for a command-line program.

        p = Parser(help = True|False)

    - Help hook: any time the library's help feature is triggered, call the
      user's function with some params and let them return something to tell
      the library which help section(s) to print, if any.

        p = Parser(help = CALLABLE)

    - That approach is flexible for the general case, but it does not speak to
      the most common type of complex use case (a program with subcommands,
      where the subcommands and help sections have a 1:1 correspondence). Some
      additional conveniences to support dispatching based on subcommands --
      or, more correctly, based on the value taken by a specific Opt.

        # For 1:1 correspondence between help sections and Opt values.
        o = Opt('task', help = 'sections')

        # For more flexibility, supply mapping from Opt value to section name.
        o = Opt('task', help = DICT)

--------
argparse-and-greed: argparse and greediness
--------

The argparse library does attach arguments greedily, but it makes no attempt
to backtrack. An example:

    Grammar:

        -z {}... <y> <y>

    Example input:

        -z A B C D E F

    Behavior:

        - Attach everything to -z.
        - Raise error because <y> not given.

--------
end-user-errors: End-user errors
--------

The problem:

    - Each Parser.parse(args) call will generate up to N failures, one per
      interpretation.

    - Ideally, we would report the error most aligned with end-user intent.

    - How do we select the error to report?

Initial ideas for mechanisms to select the most relevant error:

    - Error type, under the theory that some errors are more likely to
      convey intent about which alternative was (or was not) intended.

    - Percentage of input args matched, under regular parsing or
      perhaps forge-ahead parsing.

    - Percentage of available options present in the arguments, under the
      theory that the presence of options is one of the more telling indicators
      of intent. This metric is fairly easy to compute (a frequency distribution
      of options present).

Inferring intent from error types is tempting but not always so powerful:

    - Globally unknown options are an easy case: always select this error,
      because it's true under any interpretation.

    - One might think that an inapplicable option conveys that the current
      interpretation was not intended. But it's easy to create
      counter-examples: for example, a large N of arguments that work perfectly
      for the current interpretation, but the end-user inadvertently included
      an option for a different variant as the first argument (maybe when
      editing a prior command from shell history).

    - Invalid values might seem like an indication the current interpretation
      was intended, under the theory that the args were allocated to a slot but
      just failed in the details. But to know that with any confidence you need
      forge-ahead parsing.

The resolution is to consider how other parsers behave:

    - They always try to consume as much of the input as possible. This suggests
      that the first criterion for error-selection is S.ai.

    - Multiple interpretations can fail with the same S.ai. To resolve ties,
      consider how errors can occur (consuming an OPT, consuming a POS, or
      during final checks). For each of those cases, the error-reporting
      precedence is fairly clear-cut [listed below].

    - To resolve ties, report the error associated with the earliest
      alternative, based on the grammar.

Types of errors in precedence order, by failure source:

    - Trying to consume an OPT:

        - Globally unknown option.

        - Inapplicable option for current alternative (but known to grammar).

    - Trying to consume a POS:

        - Conversion/validation problems: params.

        - Conversion/validation problems: positionals.

        - Excess arguments.

    - Making final checks:

        - Insufficient ntimes: option.

        - Insufficient nparams.

        - Insufficient ntimes: positional.

        - Insufficient nargs.

--------
converters-validators: Converters and validators
--------

Function signatures:

    Function  | Arity | Signature
    -------------------------------------------------------
    Converter | 1     | STR            => OBJ/raise
    Validator | 3     | VAL, OPT, RES  => True/False/raise
    Dispatch  | 3     | VAL, OPT, RES  => None

--------
grammar-querying-api: Grammar querying API
--------

Grammary querying API

    - Because the Grammar can be a tree structure, the API needs good syntax to
      query for grammar elements, both for configuration needs (including the
      ability to perform bulk configurations) and for complex validations.

    - Possible approach:

        g.get(NAME, NAME, ...)          # Get one, dive-style.
        g.get(NAME, [NAME, ...], ...)   # Get multiple.

